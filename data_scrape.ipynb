{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pull genres ###\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Scrape data from genres page; See BeautifulSoup docs: https://beautiful-soup-4.readthedocs.io/en/latest/\n",
    "html_genres = requests.get('https://apps.apple.com/us/genre/ios/id36')\n",
    "soup_genres = BeautifulSoup(html_genres.text, 'html.parser')\n",
    "\n",
    "# Find all genres\n",
    "genres = soup_genres.find_all(class_=\"top-level-genre\")\n",
    "\n",
    "# Isolate genre links\n",
    "genre_links = [genre.get('href') for genre in genres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pull apps in particular genre ###\n",
    "\n",
    "# Obtain Social Networking link\n",
    "social_link = [genre_link for genre_link in genre_links if \"social-networking\" in genre_link][0]\n",
    "\n",
    "# Create alphabetic list to iterate over pages; See this post: https://stackoverflow.com/questions/16060899/alphabet-range-in-python\n",
    "import string\n",
    "alphabet = list(string.ascii_uppercase) + ['#']\n",
    "\n",
    "# Create numeric list to iterate over pages\n",
    "numbers = list(range(1,100))\n",
    "\n",
    "# Get app links for given genre\n",
    "def get_app_links(genre_link):\n",
    "  app_links = []\n",
    "  for letter in alphabet:\n",
    "    for number in numbers:\n",
    "      try:\n",
    "        html_letter = requests.get(f'{genre_link}?letter={letter}&page={number}#page')\n",
    "        soup_letter = BeautifulSoup(html_letter.text, 'html.parser')\n",
    "      except:\n",
    "        continue # Numerical page might not exist\n",
    "      links = soup_letter.find_all(\"a\", href=True)\n",
    "      sub_links = [link.get('href') for link in links]\n",
    "      app_links += [app_link for app_link in sub_links if \"https://apps.apple.com/us/app/\" in app_link]\n",
    "  return list(set(app_links)) # Remove duplicates with set, but return list\n",
    "\n",
    "# App links for Social Networking category\n",
    "app_links = get_app_links(social_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pull other apps for given developer ###\n",
    "\n",
    "other_app_links = []\n",
    "for app_link in app_links:\n",
    "  try:\n",
    "    # Find developer\n",
    "    html_app = requests.get(f'{app_link}')\n",
    "    soup_app = BeautifulSoup(html_app.text, 'html.parser')\n",
    "    links_app = soup_app.find_all(\"a\", href=True)\n",
    "    sub_links_app = [link.get('href') for link in links_app]\n",
    "    developer_links = [link for link in sub_links_app if \"https://apps.apple.com/us/developer/\" in link]\n",
    "    developer = developer_links[0]\n",
    "\n",
    "    # Pull other apps for that developer\n",
    "    html_dev = requests.get(f'{developer}')\n",
    "    soup_dev = BeautifulSoup(html_dev.text, 'html.parser')\n",
    "    links_dev = soup_dev.find_all(\"a\", href=True)\n",
    "    sub_links_dev = [link.get('href') for link in links_dev]\n",
    "    other_apps = [link for link in sub_links_dev if \"https://apps.apple.com/us/app/\" in link]\n",
    "    other_app_links += other_apps\n",
    "  except:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combine app lists ###\n",
    "app_links += other_app_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Take unique app links ###\n",
    "unique_app_links = set(app_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get app-specific data ###\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Imports for version history scrape; See Selenium Docs: https://selenium-python.readthedocs.io/getting-started.html#simple-usage; See this YouTube tutorial: https://www.youtube.com/watch?v=ATigYVyCoAE&list=PLz-0BiySzeQUuXoD4_mT3lex6HNi7f-YH\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "# Create dataframe, which will be appended to throughout the loop\n",
    "columns = ['name', 'url', 'category', 'age', 'ratings_score', 'ratings_count', 'privacy_headings', 'developer', 'price', 'purchases', 'version_history']\n",
    "df = pd.DataFrame(columns = columns)\n",
    "\n",
    "# Set up driver for version history scrape\n",
    "PATH = \"C:\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(PATH)\n",
    "\n",
    "# Collect data for all apps\n",
    "for app_link in unique_app_links:\n",
    "    # Scrape data for certain app\n",
    "    try:\n",
    "      html_app = requests.get(f'{app_link}')\n",
    "      soup_app = BeautifulSoup(html_app.text, 'html.parser')\n",
    "    except:\n",
    "      continue # Page not found\n",
    "\n",
    "    # URL\n",
    "    url = app_link\n",
    "\n",
    "    # Category\n",
    "    try:\n",
    "      links = soup_app.find_all(\"a\", href=True)\n",
    "      sub_links = [link.get('href') for link in links]\n",
    "      # Find category-specific links\n",
    "      category_links = [app_link for app_link in sub_links if \"https://itunes.apple.com/us/genre/\" in app_link]\n",
    "      category = category_links[0]\n",
    "    except:\n",
    "      category = '' # Category not found\n",
    "\n",
    "    # Name\n",
    "    try:\n",
    "      name_code = soup_app.find_all(class_=\"product-header__title app-header__title\")\n",
    "      name_list = name_code[0].text.strip()\n",
    "      name = name_list.split('\\n')[0].strip()\n",
    "    except:\n",
    "      name = '' # Name not found\n",
    "\n",
    "    # Age\n",
    "    try:\n",
    "      age = name_list.split('\\n')[1].strip()\n",
    "    except:\n",
    "      age = '' # Age not found\n",
    "\n",
    "    # Ratings\n",
    "    try:\n",
    "      ratings_code = soup_app.find_all(class_=\"we-rating-count star-rating__count\")\n",
    "      ratings = ratings_code[0].text.strip()\n",
    "      ratings_split = ratings.split('â€¢')\n",
    "      ratings_score = ratings_split[0].strip()\n",
    "      ratings_count = ratings_split[1].strip().split(' ')[0].strip()\n",
    "    except:\n",
    "      ratings_score = '' # Ratings score not found\n",
    "      ratings_count = '' # Ratings count not found\n",
    "\n",
    "    # Privacy information\n",
    "    try:\n",
    "      privacy_code = soup_app.find_all(class_=\"privacy-type__heading\")\n",
    "      privacy_headings = [heading.text for heading in privacy_code]\n",
    "    except:\n",
    "      privacy_headings = '' # Privacy information not found\n",
    "\n",
    "    # Developer\n",
    "    try:\n",
    "      links = soup_app.find_all(\"a\", href=True)\n",
    "      sub_links = [link.get('href') for link in links]\n",
    "      # Find developer-specific links\n",
    "      developer_links = [app_link for app_link in sub_links if \"https://apps.apple.com/us/developer/\" in app_link]\n",
    "      developer = developer_links[0]\n",
    "    except:\n",
    "      developer = '' # Developer not found\n",
    "\n",
    "    # Price\n",
    "    try:\n",
    "      price_code = soup_app.find_all(class_=\"inline-list__item inline-list__item--bulleted app-header__list__item--price\")\n",
    "      price = price_code[0].text.strip()\n",
    "    except:\n",
    "      price = '' # Price not found\n",
    "\n",
    "    # In-app purchases\n",
    "    try:\n",
    "      purchases_code = soup_app.find_all(class_=\"inline-list__item inline-list__item--bulleted app-header__list__item--in-app-purchase\")\n",
    "      purchases = purchases_code[0].text.strip()\n",
    "    except:\n",
    "      purchases = '' # In-app purchases not found\n",
    "\n",
    "    # Version history\n",
    "    version_bucket = []\n",
    "    try:\n",
    "      cutoff_time = time.time() + 30 # 30 second time limit to avoid excessive runtime\n",
    "      version_complete = False\n",
    "      while time.time() <= cutoff_time and version_complete != True:\n",
    "        driver.get(f'{app_link}')\n",
    "\n",
    "        element = driver.find_element(By.CLASS_NAME, 'we-modal__show.link.section__nav__see-all-link')\n",
    "        element.click()\n",
    "\n",
    "        versions = driver.find_elements(By.CLASS_NAME, 'version-history__item')\n",
    "\n",
    "        if len(versions) == 0:\n",
    "          version_complete = True\n",
    "        \n",
    "        for version in versions:\n",
    "          version_bucket.append(version.text.split(\"\\n\"))\n",
    "        version_complete = True\n",
    "\n",
    "    except:\n",
    "      version_bucket.append(\"version history not found\")\n",
    "\n",
    "    version_history = [version[1] if len(version) > 1 else version for version in version_bucket]\n",
    "\n",
    "    # Append all data to dataframe\n",
    "    df_app = pd.DataFrame([[name, url, category, age, ratings_score, ratings_count, privacy_headings, developer, price, purchases, version_history]], columns=columns)\n",
    "    df = pd.concat([df, df_app], ignore_index=True)\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export data ###\n",
    "df.to_csv('raw_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1a817c1a9ac3128d9caeb95072423615e19a09bf44268a47cd50ca436e87fce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
